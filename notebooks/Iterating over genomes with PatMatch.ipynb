{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced: Iterating over genomes with PatMatch\n",
    "\n",
    "The [previous notebook, 'Advanced: Sending PatMatch output directly to Python'](Sending%20PatMatch%20output%20directly%20to%20Python.ipynb), \n",
    "covered leveraging the the Jupyter environment to skip over needing to save a file to actually pass results from shell scripts into Python. This notebook will demonstrate using one of those approaches to iterate over several genomes.\n",
    "\n",
    "## Preparing\n",
    "\n",
    "Similar to the previous notebook, in order to insure everything is all set, act as if this is a new session in this Jupyter environment, and run the next cell so that you can start stepping through the preparation steps by first getting a sequence file. Plus, you'll get the files for scripts to convert it to dataframe and plot sites across a chromosome and import the main functions of those scripts. \n",
    "\n",
    "Repeating these steps if you had already done so this session will cause no harm, and so go ahead and run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 87344  100 87344    0     0   236k      0 --:--:-- --:--:-- --:--:--  236k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 18722  100 18722    0     0    99k      0 --:--:-- --:--:-- --:--:--   99k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://downloads.yeastgenome.org/sequence/S288C_reference/chromosomes/fasta/chrmt.fsa\n",
    "!curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/patmatch-utilities/patmatch_results_to_df.py\n",
    "from patmatch_results_to_df import patmatch_results_to_df\n",
    "!curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/plot_sites/plot_sites_position_across_chromosome.py\n",
    "from plot_sites_position_across_chromosome import plot_sites_position_across_chromosome "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the sequences of two other mitochondrial genomes will be retrieved.\n",
    "\n",
    "Reference for the additional sequence data:  \n",
    "- [Contrasting evolutionary genome dynamics between domesticated and wild yeasts.\n",
    "Yue JX, Li J, Aigrain L, Hallin J, Persson K, Oliver K, BergstrÃ¶m A, Coupland P, Warringer J, Lagomarsino MC, Fischer G, Durbin R, Liti G. Nat Genet. 2017 Jun;49(6):913-924. doi: 10.1038/ng.3847. Epub 2017 Apr 17. PMID: 28416820](https://www.ncbi.nlm.nih.gov/pubmed/28416820)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0    601      0 --:--:-- --:--:-- --:--:--   599\n",
      "100 18692  100 18692    0     0  42385      0 --:--:-- --:--:-- --:--:-- 42385\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2170      0 --:--:-- --:--:-- --:--:--  2170\n",
      "100 18399  100 18399    0     0  80697      0 --:--:-- --:--:-- --:--:-- 80697\n"
     ]
    }
   ],
   "source": [
    "# Prepare for getting PacBio (Yue et al 2017 sequences)\n",
    "#make a list of the strain designations\n",
    "yue_et_al_strains = [\"CBS432\",\"N44\"]\n",
    "# Get & unpack the genome sequences from strains \n",
    "import os\n",
    "genomes = []\n",
    "expected_resulting_file = \"N44_mito.genome.fa\"\n",
    "if not os.path.isfile(expected_resulting_file):\n",
    "    for s in yue_et_al_strains:\n",
    "        !curl -OL http://yjx1217.github.io/Yeast_PacBio_2016/data/Mitochondrial_Genome/{s}.mt.genome.fa.gz\n",
    "        !gunzip -f {s}.mt.genome.fa.gz\n",
    "        # rename the files to follow the convention used for SGD reference\n",
    "        !mv {s}.mt.genome.fa {s}_mito.genome.fsa\n",
    "        genomes.append(s+\"_mito.genome.fsa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add identifiers to each description line so results for each strain clear later. The reference from the Saccharomyces Genome database will be tagged 'SGD_REFmito'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "import os\n",
    "# add identifiers to each description line so results for each strain clear later\n",
    "def add_strain_id_to_description_line(file,strain_id):\n",
    "    '''\n",
    "    Takes a file and edits every description line to add \n",
    "    strain_id after the caret.\n",
    "    \n",
    "    Saves the fixed file\n",
    "    '''\n",
    "    import sys\n",
    "    output_file_name = \"temp.txt\"\n",
    "    # prepare output file for saving so it will be open and ready\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "\n",
    "        # read in the input file\n",
    "        with open(file, 'r') as input_handler:\n",
    "            # prepare to give feeback later or allow skipping to certain start\n",
    "            lines_processed = 0\n",
    "\n",
    "            for line in input_handler:\n",
    "                lines_processed += 1\n",
    "                if line.startswith(\">\"):\n",
    "                    rest_o_line = line.split(\">\")\n",
    "                    new_line = \">\"+strain_id +\"\\n\"\n",
    "                else:\n",
    "                    new_line = line\n",
    "                \n",
    "                # Send text to output\n",
    "                output_file.write(new_line)\n",
    "\n",
    "    \n",
    "    # replace the original file with edited\n",
    "    !mv temp.txt {file}\n",
    "    # Feedback\n",
    "    sys.stderr.write(\"\\n{} has had identifiers added.\".format(file))\n",
    "\n",
    "files_tagged = 0\n",
    "for g in genomes:\n",
    "    add_strain_id_to_description_line(g, g.split('.genome.fsa')[0])\n",
    "    files_tagged += 1\n",
    "# Feedback\n",
    "sys.stderr.write(\"\\n{} sets of strain identifiers added.\".format(files_tagged))\n",
    "# Edit the description line for the SGD reference to be clear\n",
    "!sed -i '1s/.*/>SGD_REFmito/' chrmt.fsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of the genomes based on the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chrmt.fsa', 'N44_mito.genome.fsa', 'CBS432_mito.genome.fsa']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_pat_to_check = \".fsa\"\n",
    "genomes = []\n",
    "import os\n",
    "import fnmatch\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, '*'+fn_pat_to_check):\n",
    "        genomes.append(file)\n",
    "genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteraring over the genomes with PatMatch searching for sequence patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "promoter_pattern = \"DDWDWTAWAAGTARTADDDD\"\n",
    "from patmatch_results_to_df import patmatch_results_to_df\n",
    "dfs = []\n",
    "for seq_file in genomes:\n",
    "    seq_file_fullpath = genomes_dirn + \"/\" + seq_file\n",
    "    !perl patmatch_1.2/unjustify_fasta.pl {seq_file_fullpath}\n",
    "    output = !perl patmatch_1.2/patmatch.pl -c {promoter_pattern} {seq_file_fullpath+\".prepared\"}\n",
    "    !rm {seq_file_fullpath+\".prepared\"}\n",
    "    df_pat = patmatch_results_to_df(output.n, pattern=promoter_pattern, name=\"promoter\")\n",
    "    df_pat[\"strain\"] = seq_file.split(new_extension)[0]\n",
    "    cols = df_pat.columns.tolist()\n",
    "    n = int(cols.index('strain'))\n",
    "    cols = [cols[n]] + cols[:n] + cols[n+1:]\n",
    "    df_pat = df_pat[cols]\n",
    "    dfs.append(df_pat)\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualize each genomes positions with x-axis matching particular genome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataf in fs:\n",
    "    plot_sites_position_across_chromosome(dataf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `%%capture` is used in the above cell to stop the output from accumulating to a large size when many proteins are analyzed, the results are checked in the cell following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>FASTA_id</th>\n",
       "      <th>hit_number</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>strand</th>\n",
       "      <th>matching pattern</th>\n",
       "      <th>query pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613</td>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613|NO...</td>\n",
       "      <td>1</td>\n",
       "      <td>promoter-1</td>\n",
       "      <td>116</td>\n",
       "      <td>97</td>\n",
       "      <td>-1</td>\n",
       "      <td>AAAAATATAAGTAATATATA</td>\n",
       "      <td>DDWDWTAWAAGTARTADDDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613</td>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613|NO...</td>\n",
       "      <td>1</td>\n",
       "      <td>promoter-2</td>\n",
       "      <td>116</td>\n",
       "      <td>97</td>\n",
       "      <td>-1</td>\n",
       "      <td>AAAAATATAAGTAATATATA</td>\n",
       "      <td>DDWDWTAWAAGTARTADDDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613</td>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613|NO...</td>\n",
       "      <td>1</td>\n",
       "      <td>promoter-3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>-1</td>\n",
       "      <td>AAAAATATAAGTAATATATA</td>\n",
       "      <td>DDWDWTAWAAGTARTADDDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613</td>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613|NO...</td>\n",
       "      <td>1</td>\n",
       "      <td>promoter-4</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>-1</td>\n",
       "      <td>AAAAATATAAGTAATATATA</td>\n",
       "      <td>DDWDWTAWAAGTARTADDDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613</td>\n",
       "      <td>yHMPu5000035690_candida_vartiovaarae_160613|NO...</td>\n",
       "      <td>1</td>\n",
       "      <td>promoter-5</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>AAAAATATAAGTAATATATA</td>\n",
       "      <td>DDWDWTAWAAGTARTADDDD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        strain  \\\n",
       "0  yHMPu5000035690_candida_vartiovaarae_160613   \n",
       "1  yHMPu5000035690_candida_vartiovaarae_160613   \n",
       "2  yHMPu5000035690_candida_vartiovaarae_160613   \n",
       "3  yHMPu5000035690_candida_vartiovaarae_160613   \n",
       "4  yHMPu5000035690_candida_vartiovaarae_160613   \n",
       "\n",
       "                                            FASTA_id hit_number      hit_id  \\\n",
       "0  yHMPu5000035690_candida_vartiovaarae_160613|NO...          1  promoter-1   \n",
       "1  yHMPu5000035690_candida_vartiovaarae_160613|NO...          1  promoter-2   \n",
       "2  yHMPu5000035690_candida_vartiovaarae_160613|NO...          1  promoter-3   \n",
       "3  yHMPu5000035690_candida_vartiovaarae_160613|NO...          1  promoter-4   \n",
       "4  yHMPu5000035690_candida_vartiovaarae_160613|NO...          1  promoter-5   \n",
       "\n",
       "  start end strand      matching pattern         query pattern  \n",
       "0   116  97     -1  AAAAATATAAGTAATATATA  DDWDWTAWAAGTARTADDDD  \n",
       "1   116  97     -1  AAAAATATAAGTAATATATA  DDWDWTAWAAGTARTADDDD  \n",
       "2    55  74     -1  AAAAATATAAGTAATATATA  DDWDWTAWAAGTARTADDDD  \n",
       "3    55  74     -1  AAAAATATAAGTAATATATA  DDWDWTAWAAGTARTADDDD  \n",
       "4    70  89      1  AAAAATATAAGTAATATATA  DDWDWTAWAAGTARTADDDD  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('hit_number', ascending=False, inplace=True)\n",
    "largest_hit_num_by_id_df = df.groupby('FASTA_id').head(1)\n",
    "largest_hit_num_by_id_df = largest_hit_num_by_id_df.groupby('strain').head(1).reset_index(drop=True)\n",
    "largest_hit_num_by_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>FASTA_id</th>\n",
       "      <th>hit_number</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>strand</th>\n",
       "      <th>matching pattern</th>\n",
       "      <th>query pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>2</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>yHMPu5000035672_phaffomyces_thermotolerans_160613</td>\n",
       "      <td>metschnikowia_lockheadii|loc-_s55</td>\n",
       "      <td>2</td>\n",
       "      <td>promoter-1</td>\n",
       "      <td>105170</td>\n",
       "      <td>22252</td>\n",
       "      <td>1</td>\n",
       "      <td>TGATTTAAAAGTAATAATAG</td>\n",
       "      <td>DDWDWTAWAAGTARTADDDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>4</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   strain  \\\n",
       "count                                                 320   \n",
       "unique                                                320   \n",
       "top     yHMPu5000035672_phaffomyces_thermotolerans_160613   \n",
       "freq                                                    1   \n",
       "\n",
       "                                 FASTA_id  hit_number      hit_id   start  \\\n",
       "count                                 320         320         320     320   \n",
       "unique                                320          17          43     320   \n",
       "top     metschnikowia_lockheadii|loc-_s55           2  promoter-1  105170   \n",
       "freq                                    1          88          50       1   \n",
       "\n",
       "          end  strand      matching pattern         query pattern  \n",
       "count     320     320                   320                   320  \n",
       "unique    320       2                   297                     1  \n",
       "top     22252       1  TGATTTAAAAGTAATAATAG  DDWDWTAWAAGTARTADDDD  \n",
       "freq        1     205                     4                   320  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_hit_num_by_id_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-or-???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "my_pattern= \"DDWDWTAWAAGTARTADDDDCCA\"\n",
    "output = !perl ../patmatch_1.2/patmatch.pl -c {my_pattern} Pila.1_5.fa.prepared \n",
    "#Normally, send output to patmatch_results_to_df.py with the `.n` attribute of IPython.utils.text.SList ,\n",
    "# but was getting warnings about size among the output text, and so removed those before sending \n",
    "# to patmatch_results_to_df.py .\n",
    "warning = \"Warning: recSearchFile: Record longer than buffer size (10000000) has been split\\n\"\n",
    "output_wo_warnings = output.n.replace(warning,'')\n",
    "df = patmatch_results_to_df(output_wo_warnings, pattern=my_pattern, name=\"test_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sites_df = df\n",
    "plot_sites_position_across_chromosome(sites_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a plot. (If by any chance you don't see a plot and also don't see an error, just try running the cell again.) But it isn't much to look at because there is only one type of sequence element. \n",
    "\n",
    "However, by combining steps seen above and a little more power of Pandas to concatenate the dataframes, you can quickly add a lot of other sites easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../patmatch_1.2/patmatch.pl -c \"GAATTC\" chrmt.fsa.prepared > ecori.out\n",
    "!perl ../patmatch_1.2/patmatch.pl -c \"GGATCC\" chrmt.fsa.prepared > bamhi.out\n",
    "!perl ../patmatch_1.2/patmatch.pl -c \"TCTAGA\" chrmt.fsa.prepared > xbai.out\n",
    "%run patmatch_results_to_df.py ecori.out --pattern GAATTC -name EcoRI -dfo ecori_df.pkl\n",
    "%run patmatch_results_to_df.py bamhi.out --pattern GGATCC -name BamHI -dfo bamhi_df.pkl\n",
    "%run patmatch_results_to_df.py xbai.out --pattern TCTAGA -name XbaI -dfo xbai_df.pkl\n",
    "ecori_df = pd.read_pickle(\"ecori_df.pkl\")\n",
    "bamhi_df = pd.read_pickle(\"bamhi_df.pkl\")\n",
    "xbai_df = pd.read_pickle(\"xbai_df.pkl\")\n",
    "df_res = pd.concat([ecori_df,bamhi_df,xbai_df], ignore_index=True)\n",
    "df_res = df_res.rename(columns={'hit_id':'sys_gene_id'})\n",
    "df_new = pd.concat([df,df_res], ignore_index=True)\n",
    "%matplotlib inline\n",
    "sites_df = df_new\n",
    "plot_sites_position_across_chromosome(sites_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trick of putting `%%capture` on first line from [here](https://stackoverflow.com/a/23692951/8508004) to suppress the output from `patmatch_results_to_df` function from filling up cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 s, sys: 14.3 s, total: 45.9 s\n",
      "Wall time: 26min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import os\n",
    "\n",
    "from patmatch_results_to_df import patmatch_results_to_df\n",
    "\n",
    "genomes_dir = 'GENOMES_ASSEMBLED'\n",
    "promoter_pattern = \"DDWDWTAWAAGTARTADDDD\"\n",
    "\n",
    "best_matches_dict = {\n",
    "                    'FASTA_file':[],\n",
    "                    'candidate_id':[],\n",
    "                    'candidate_num_matches':[],\n",
    "                    'candidate_rough_size':[],\n",
    "                    'alt_id':[],\n",
    "                    'alt_num_matches':[],\n",
    "                    'alt_rough_size':[],\n",
    "                    'alt`_id':[],\n",
    "                    'alt`_num_matches':[],\n",
    "                    'alt`_rough_size':[],\n",
    "                    }\n",
    "\n",
    "for file in os.listdir(genomes_dir):\n",
    "    if fnmatch.fnmatch(file, '*.re.fa'):\n",
    "        !perl patmatch_1.2/unjustify_fasta.pl {genomes_dir}/{file}\n",
    "        #os.remove(os.path.join(genomes_dir, file)) #left over from development\n",
    "        output = !perl patmatch_1.2/patmatch.pl -c {promoter_pattern} {genomes_dir}/{file}.prepared\n",
    "        os.remove(os.path.join(genomes_dir, file+\".prepared\")) #delete file made for PatMatch\n",
    "        df = patmatch_results_to_df(output.n, pattern=promoter_pattern, name=\"promoter\")\n",
    "        df['start'] = df['start'].apply(\n",
    "        pd.to_numeric, errors='coerce') #necessary for using `max` on 'start' column\n",
    "        df.sort_values('hit_number', ascending=False, inplace=True)\n",
    "        best_candidate_id = df.iloc[0][\"FASTA_id\"] #best candidate\n",
    "        best_candidate_num_matches = df.iloc[0][\"hit_number\"] #number of matches on best candidate\n",
    "        best_df= df[df[\"FASTA_id\"] == best_candidate_id]#sets up for next line\n",
    "        best_candidate_max_start = best_df.start.max(0)#rough indication of size of best candidate\n",
    "        df_group = df.groupby('FASTA_id').head(1)\n",
    "        secnd_best_candidate_id = df_group.iloc[1][\"FASTA_id\"] #2nd-best candidate\n",
    "        secnd_best_candidate_num_matches = df_group.iloc[1][\"hit_number\"] #number of matches on 2nd-best candidate\n",
    "        secnd_best_df= df[df[\"FASTA_id\"] == secnd_best_candidate_id]#sets up for next line\n",
    "        secnd_best_candidate_start = secnd_best_df.start.max(0)#rough indication of size for 2nd-best candidate\n",
    "        third_best_candidate_id = df_group.iloc[2][\"FASTA_id\"] #3rd-best candidate\n",
    "        third_best_candidate_num_matches = df_group.iloc[2][\"hit_number\"] #number of matches on 3rd-best candidate\n",
    "        third_best_df= df[df[\"FASTA_id\"] == third_best_candidate_id]#sets up for next line\n",
    "        third_best_candidate_start = third_best_df.start.max(0)#rough indication of size for 3rd-best candidate\n",
    "        best_matches_dict['FASTA_file'].append(file)\n",
    "        best_matches_dict['candidate_id'].append(best_candidate_id)\n",
    "        best_matches_dict['candidate_num_matches'].append(best_candidate_num_matches)\n",
    "        best_matches_dict['candidate_rough_size'].append(best_candidate_max_start)\n",
    "        best_matches_dict['alt_id'].append(secnd_best_candidate_id)\n",
    "        best_matches_dict['alt_num_matches'].append(secnd_best_candidate_num_matches)\n",
    "        best_matches_dict['alt_rough_size'].append(secnd_best_candidate_start)\n",
    "        best_matches_dict['alt`_id'].append(third_best_candidate_id)\n",
    "        best_matches_dict['alt`_num_matches'].append(third_best_candidate_num_matches)\n",
    "        best_matches_dict['alt`_rough_size'].append(third_best_candidate_start)\n",
    "df = pd.DataFrame(best_matches_dict, columns = ['FASTA_file',\n",
    "                                                'candidate_id',\n",
    "                                                'candidate_num_matches',\n",
    "                                                'candidate_rough_size',\n",
    "                                                'alt_id',\n",
    "                                                'alt_num_matches',\n",
    "                                                'alt_rough_size',\n",
    "                                                'alt`_id',\n",
    "                                                'alt`_num_matches',\n",
    "                                                'alt`_rough_size'\n",
    "                                                ])\n",
    "\n",
    "df.to_pickle(\"candidate_mitochondrial_genomes_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('candidate_mitochondrial_genomes_df_as_txt.tsv', sep='\\t',index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Patmatch and passing the results to Python without creating an output file intermediate\n",
    "\n",
    "#### Option 1\n",
    "\n",
    "First we'll do one of the several methods I have found to do this and show how to go to the next step entirely. This first example uses an approach illustrated [here](https://stackoverflow.com/a/42703609/8508004).  The result that is returned is of the type `IPython.utils.text.SList`, which offers some handy utility attributes associated with it as detailed [here](http://ipython.readthedocs.io/en/stable/api/generated/IPython.utils.text.html#IPython.utils.text.SList)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = !perl ../patmatch_1.2/patmatch.pl -c \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That performed the matching step without generating an intermediate file. Next, run the next cell to combine this with use of main function of `patmatch_results_to_df.py` as illustrated in the [previous notebook, 'PatMatch with more Python'](PatMatch with more Python.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patmatch_results_to_df.py with the `.n` attribute of IPython.utils.text.SList\n",
    "my_pattern= \"DDWDWTAWAAGTARTADDDD\"\n",
    "df = patmatch_results_to_df(output.n, pattern=my_pattern, name=\"promoter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option has the distinction that all the steps in it can be combined in one cell of the notebook. This is because the `!<command>` approach makes a temporary shell outside of the notebook environment to which it sends the command after the exclamation site. After that command is processed and any communication handled, that subshell where it ran is discarded. Given the transient nature of this environment you'll find `!cd` never seems to work as they discuss [here](http://ipython.readthedocs.io/en/stable/interactive/magics.html), search `!cd` to find the pertinent section where they also show you the line magics solution. ([Here](https://jakevdp.github.io/PythonDataScienceHandbook/01.05-ipython-and-shell-commands.html) is another good resource in this regard.)\n",
    "\n",
    "This option can be worked into a utility function that includes the preparation step. This is very handy if trying a lot of patterns and/or sequences because could easily be called in a loop and supplied with different parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patmatch_query(pattern, seq_file, name):\n",
    "    '''\n",
    "    function that will work in Jupyter lab notebooks to run Patmatch query.\n",
    "    \n",
    "    Requires pattern and sequence file. Plus a name to use to refer to \n",
    "    instances of pattern in output.\n",
    "    \n",
    "    Returns dataframe of results.\n",
    "    '''\n",
    "    from patmatch_results_to_df import patmatch_results_to_df\n",
    "\n",
    "    !perl ../patmatch_1.2/unjustify_fasta.pl {seq_file}\n",
    "    output = !perl ../patmatch_1.2/patmatch.pl -c {pattern} {seq_file+\".prepared\"}\n",
    "    #!rm {seq_file+\".prepared\"} # OPTIONAL deleting of prepared file.\n",
    "    df = patmatch_results_to_df(output.n, pattern=pattern, name=name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I commented out deleting the preparation file in the function in the above cell because I want to use it later on in this notebook, but it would be useful to include normally to not generate a lot of uncessary files.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = patmatch_query(my_pattern, \"chrmt.fsa\", \"promoter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "The additional options for passing the results demonstrated below instead rely on cell magics, and so the output needs to be captured from a cell before the next steps can be undertaken in an additional cell. While not a big deal that extra cells are involved, I find the `!<command>` approach can be nice for streamlining things when making mini-pipelines/workflows using the Jupyter environment as a 'glue' to merge Python and command line use. \n",
    "\n",
    "The additional options for passing the results will be stepped through in a manner similar to 'Option 1' using different approaches for step 1 each time and step #2 varied to handle as necessary.\n",
    "\n",
    "#### Option 2\n",
    "\n",
    "In this option, [`%%capture` cell magics](http://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-capture) is used, and then using the attributes of the `utils.cpature` object you can easily get the stdout and/or stderr as a string, see [here]( http://ipython.readthedocs.io/en/stable/api/generated/IPython.utils.capture.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture out\n",
    "!perl ../patmatch_1.2/patmatch.pl -c \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patmatch_results_to_df.py with the `.stdout` attribute of `utils.cpature`\n",
    "my_pattern= \"DDWDWTAWAAGTARTADDDD\"\n",
    "df = patmatch_results_to_df(out.stdout, pattern=my_pattern, name=\"promoter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3\n",
    "\n",
    "In this option, a varation of `%%bash` cell magic is used to send the output to a variable as illustrated [here](https://stackoverflow.com/a/24776049/8508004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out output\n",
    "perl ../patmatch_1.2/patmatch.pl -c \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patmatch_results_to_df.py by passing the stdout to a varible using %%bash cell magic\n",
    "my_pattern= \"DDWDWTAWAAGTARTADDDD\"\n",
    "df = patmatch_results_to_df(output, pattern=my_pattern, name=\"promoter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 4 (<font color='red'>** NEVERMIND, THIS DOESN'T SEEM TO WORK.**</font>** NEVERMIND, THIS DOESN'T SEEM TO WORK.**)\n",
    "\n",
    "In this option, IPython's output caching system as summarized [here](https://stackoverflow.com/a/27952661/8508004) is used. Step#1 requires nothing different than the normal command that sends the output to the output stream of the cell. The trick comes in step#2 where that output is used by pointing to it with an underscore. <font color='red'>** DESPITE THE FACT I HAD NOTED THIS APPROACH WORKED ONCE IN THE PAST WITH A RESULT FROM THE SHELL, IT DOESN'T SEEM TO WORK AND MAYBE I WAS FOOLED BY SOMETHING IN THE NAMESPACE?!?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../patmatch_1.2/patmatch.pl -c \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patmatch_results_to_df.py by reference the output of the previous cell using IPython's 'output caching system'\n",
    "my_pattern= \"DDWDWTAWAAGTARTADDDD\"\n",
    "df = patmatch_results_to_df(_, pattern=my_pattern, name=\"promoter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
